\chapter{Metodologia}\label{cap:proposta}

Esta seção descreve a metodologia proposta para a tarefa de classificação da OA de joelho a partir de radiografias. A principal abordagem desta pesquisa consiste no uso de \textit{transfer learning} para aproveitar o conhecimento já obtido por modelos pré-treinados e melhorar a performance da predição final.

\section{Coleta de dados}

A escolha e coleta dos dados é a primeira tarefa a ser realizada quando o objetivo é treinar um modelo de aprendizado profundo, incluindo redes neurais artificiais e vision transformers. Um conjunto de dados adequado é essencial para que o modelo tenha uma boa performance e seja útil para se tornar uma ferramenta de suporte no diagnóstico de OA de joelho. O conjunto de dados foi obtido a partir da plataforma Kaggle \cite{dataset-kaggle}, uma fonte amplamente reconhecida por fornecer dados de alta qualidade e de domínio público para estudos acadêmicos e projetos de aprendizado de máquina. O conjunto de dados escolhido é baseado na Osteoarthritis Initiative (OAI), um estudo observacional multicêntrico de dez anos de homens e mulheres, patrocionado pelo National Institutes of Health (NIH), com o objetivo de permitir uma melhor compreensão da prevenção e tratamento da osteoartrite de joelho \cite{oai}. Este conjunto contém radiografias de joelhos, juntamente com suas respectivas classificações de severidade da OA, conforme o sistema de Kellgren/Lawrence. Este dataset foi selecionado por sua relevância na plataforma, fornecendo uma base sólida para o treinamento dos modelos de RNCs e ViTs propostos nesta pesquisa. A \autoref{dataset-distribuition} ilustra a distribuição do conjunto de dados entre treino, teste e validação.

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{figs/num-imagens-por-escala-kl.png}
    \caption{Número de imagens em cada classe do conjunto de dados}
    \label{dataset-distribuition}
\end{figure}

O conjunto de dados contém quatro pastas nomeadas ``auto\_test'', ``test'', ``train'' e ``val'', cada uma contendo as subpastas com imagens 224x224 representando cada um dos graus de KL. O dataset foi dividido entre dados de treino, teste e validação, com uma proporção de 7:2:1. O conjunto de treino é usado para treinar os modelos e consiste na maior proporção de imagens. O conjunto de validação é usado para ajustar os hiperparâmetros do modelo e monitorar o seu desempenho, enquanto o conjunto de teste é usado após o treinamento completo do modelo, para medir o desempenho final e verificar sua capacidade de generalização em dados completamente novos.

\section{Pré-processamento das imagens}

O pré-processamento de imagens de raio-X é crucial para melhorar a qualidade e facilitar a análise automatizada pelos modelos. Para isso, algumas técnicas devem ser utilizadas, incluindo:

\subsection{Normalização}

A normalização de dados visa ajustar os valores para um intervalo padrão, melhorando a consistência dos dados e a eficiências dos modelos treinados. Para as radiografias, os pixels devem ter seus valores transformados para o intervalo entre 0 e 1.

\subsection{Equalização de Histograma}

A equalização de histograma é um método de processamento de imagem que busca melhorar o contraste e a visibilidade dos detalhes em uma imagem. Para isso, esta técnica redistribui os níveis de cinza da imagem, de forma que a distribuição dos valores de intensidade seja mais uniforme. Isso é feito calculando o histograma acumulado da imagem original e utilizando-o para redistribuir os valores de cada pixel. Em particular, a equalização de histograma é útil para radiografias, onde a variação de intensidade pode ser sutil e a distinção entre diferentes graus de KL pode ser difícil.

Dada uma imagem \( I(x, y) \) com intensidades de pixel \( i \in \{0, 1, \dots, L-1\} \) e número total de pixels \( N \), onde \( x \) e \( y \) são as coordenadas do pixel, e \( L \) é o número de níveis de intensidade (normalmente \( L = 256 \) para imagens de 8 bits), a probabilidade de ocorrência de cada intensidade \( i \) é calculada como:

\[
p(i) = \frac{n(i)}{N}
\]

onde \( n(i) \) é o número de pixels com intensidade \( i \) na imagem. O histograma acumulado \( H \) é então calculado como:

\[
H(i) = \sum_{j=0}^{i} p(j)
\]

O novo valor de intensidade \( j \) para um pixel com intensidade \( i \) é calculado como:

\[
j = (L-1) \times H(i)
\]

onde \( L - 1 \) garante que o novo valor esteja no intervalo de intensidade da imagem. O resultado da equalização é normalmente arredondado para o valor inteiro mais próximo.

\subsection{Aumento de dados}

A ideia desta técnica é expandir artificialmente o tamanho e a variabilidade de um conjunto de dados, principalmente quando o volume de dados disponível é limitado. Isso torna os modelos mais robustos e genéricos, prevenindo \textit{overfitting} e melhorando o desempenho em dados novos. As técnicas de aumento de dados que serão utilizadas nas radiografias são: rotação e reflexão (espelhamento) horizontal.

\section{Arquitetura do modelo de Rede Neural Convolucional}

As redes neurais convolucionais possuem um papel muito relevante no contexto de inteligência artificial, especialmente em tarefas de visão computacional devido à sua capacidade de extrair características relevantes de imagens de forma automática, sem qualquer intervenção manual. Sua arquitetura é especialmente eficaz para reconhecer e classificar objetos em imagens complexas, inclusive em radiografias, com o intuito de auxiliar no processo de diagnóstico médico. As RNCs conseguem identificar variações sutis que podem estar associadas a condições patológicas, como é o caso da osteoartrite de joelho, onde as variações entre os graus de KL reside no espaçamento articular da junção do joelho.

Fazer o treinamento de uma RNC sem nenhum conhecimento prévio do modelo é custoso em termos de quantidade de dados necessário, consumo de recursos computacionais e tempo. Para resolver este problema, o uso de \textit{transfer learning} é essencial, pois permite aproveitar modelos já treinados em grandes conjuntos de dados genéricos, como o ImageNet, e adaptá-los para o conjunto de dados específico para o problema. Ao utilizar o \textit{transfer learning}, as primeiras camadas do modelo, que capturam características gerais da imagem, são congeladas, enquanto as camadas finais são ajustadas para a tarefa específica, tal processo é chamado de \textit{fine-tuning}. Isso economiza tempo e recursos computacionais e aumenta a eficácia do treinamento, resultando em modelos que podem fornecer diagnósticos precisos mesmo com volumes menores de dados disponíveis. Nos últimos anos, algumas arquiteturas performaram muito bem em algumas tarefas, como por exemplo a ResNet, VGG, Inception (GoogLeNet) e DenseNet. A arquitetura para os modelos de RNC pode ser vista na Figura \ref{modelo rnc}.

\subsection{VGG (Visual Geometry Group Network)}

Os modelos VGG foram introduzidos pelo \textit{Visual Geometry Group} da Universidade de Oxford por \cite{Simonyan2015}, que depois serviu como base para a competição do \textit{ImageNet} em 2014, quando conquistaram o primeiro e segundo lugar na época. A arquitetura VGG é conhecida por sua simplicidade e profundidade, utilizando filtros convolucionais pequenos (3×3) empilhados em camadas profundas, variando de 11 a 19 camadas. O objetivo dos autores era explorar o impacto da profundidade na performance do modelo, e eles descobriram que redes neurais mais profundas superavam redes mais rasas, desde que treinadas adequadamente.

A arquitetura VGG processa imagens RGB de 224×224 pixels, utilizando uma série de camadas convolucionais seguidas por camadas de \textit{pooling}, onde cada camada contém um número crescente de filtros 3×3. O \textit{stride} é fixo em 1 pixel, e o \textit{padding} é utilizado para manter a dimensão da imagem. Após as camadas convolucionais, são aplicadas camadas de \textit{max-pooling} com um tamanho de 2×2 e \textit{stride} de 2, reduzindo a dimensão da imagem pela metade. Por fim, são adicionadas três camadas totalmente conectadas (ou \textit{fully connected} do inglês), seguidas por uma camada de saída com ativação \textit{softmax} para classificação. Além disso, as camadas escondidas são ativadas por funções ReLU, reponsáveis por introduzir a não-linearidade no modelo.

A tabela \ref{vgg-arch} apresenta a configuração das arquiteturas VGG-16 e VGG-19, com um total de 16 e 19 camadas, respectivamente. Ambas se destacaram na competição do \textit{ImageNet} e são amplamente utilizadas devido à sua performance em tarefas de classificação de imagens médicas \citep{Saini2023, Sitaula2021}. Por esse motivo, estas arquiteturas serão utilizadas nesta pesquisa como comparação com os demais modelos.

% TODO: dar exemplos bem-sucedidos do uso de VGG em radiografias

\begin{table}[h]
    \centering
    \footnotesize
    \begin{tabular}{|c|c|}
        \hline
        \textbf{VGG-16} & \textbf{VGG-19} \\
        \hline
        16 camadas & 19 camadas \\
        \hline
        \multicolumn{2}{|c|}{imagem RGB de entrada (224 x 224)} \\
        \hline
        conv3-64 & conv3-64 \\
        conv3-64 & conv3-64 \\
        \hline
        \multicolumn{2}{|c|}{maxpool} \\
        \hline
        conv3-128 & conv3-128 \\
        conv3-128 & conv3-128 \\
        \hline
        \multicolumn{2}{|c|}{maxpool} \\
        \hline
        conv3-256 & conv3-256 \\
        conv3-256 & conv3-256 \\
        conv3-256 & conv3-256 \\
         & \textbf{conv3-256} \\
        \hline
        \multicolumn{2}{|c|}{maxpool} \\
        \hline
        conv3-512 & conv3-512 \\
        conv3-512 & conv3-512 \\
        conv3-512 & conv3-512 \\
         & \textbf{conv3-512} \\
        \hline
        \multicolumn{2}{|c|}{maxpool} \\
        \hline
        conv3-512 & conv3-512 \\
        conv3-512 & conv3-512 \\
        conv3-512 & conv3-512 \\
         & \textbf{conv3-512} \\
        \hline
        \multicolumn{2}{|c|}{maxpool} \\
        \hline
        \multicolumn{2}{|c|}{FC-4096} \\
        \hline
        \multicolumn{2}{|c|}{FC-4096} \\
        \hline
        \multicolumn{2}{|c|}{FC-1000} \\
        \hline
        \multicolumn{2}{|c|}{softmax} \\
        \hline
    \end{tabular}
    \caption{Configuração dos modelos VGG-16 e VGG-19. Os parâmetros de cada camada convolucional são denotados por "conv<tamanho do campo receptivo>-<número de canais>". A função de ativação ReLU não é exibida por motivos de simplicidade.}
    \label{vgg-arch}
\end{table}

\subsection{ResNet (Residual Network)}

\cite{He2016} venceram a competição ILSVRC 2015 com a arquitetura \textit{Residual Network} (\textit{ResNet}), que introduziu a ideia de blocos residuais e alcançou uma taxa de erro de 3,57\% no conjunto de validação do \textit{ImageNet} com um \textit{ensemble} de seus modelos. Os autores abordaram o problema da degradação de desempenho: conforme a profundidade da rede aumentava, a acurácia saturava e começava a diminuir. Para resolver, eles introduziram a ideia de conexões de atalho (\textit{skip connections}) entre as camadas, onde o sinal de entrada de uma camada é somado ao sinal de saída de uma camada subsequente (\autoref{residual-learning}).

Formalmente, considerando que o objetivo de uma rede neural é aprender uma função \( H(x) \), onde \( x \) é a entrada, a ResNet propõe que a rede aprenda uma função residual \( F(x) = H(x) - x \), onde a entrada \( x \) é adicionada à saída \( H(x) \), reformulando a função de aprendizado como \( H(x) = F(x) + x \). Essa abordagem permite que a rede aprenda funções de identidade mais facilmente, facilitando o treinamento de redes mais profundas sem adicionar complexidade.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\linewidth]{figs/residual-connection.png}
    \caption{Aprendizado residual}
    \label{residual-learning}
\end{figure}

A arquitetura ResNet é composta por pilhas de blocos residuais que consistem em duas camadas convolucionais, com um \textit{Batch Normalization} e uma função de ativação ReLU entre elas. As camadas convolucionais utilizam filtros de tamanho 3×3, com um \textit{stride} de 1 e \textit{padding} de 1, para manter a dimensão da imagem. A saída do bloco residual é então somada à entrada original, permitindo que o modelo aprenda a função residual. A rede termina com uma camada de \textit{average pooling} global e uma camada totalmente conectada (ou \textit{fully connected} do inglês) com ativação \textit{softmax} para classificação.

A tabela \ref{resnet-arch} apresenta a configuração das arquiteturas ResNet-34, ResNet-50 e ResNet-101, que são variantes da ResNet com diferentes profundidades. Essas arquiteturas foram escolhidas devido à sua popularidade e eficácia em tarefas de classificação de imagens, especialmente em radiografias \citep{Leung2020}.

% TODO: dar exemplos bem-sucedidos do uso de ResNet em radiografias

\begin{table}[h]
    \centering
    \footnotesize
    \begin{tabular}{|c|c|c|c|c|}
        \hline
        \textbf{Camada} & \textbf{Tamanho da saída} & \textbf{34 camadas} & \textbf{50 camadas} & \textbf{101 camadas} \\
        \hline
        conv1 & 112×112 & \multicolumn{3}{c|}{7×7, 64, stride 2} \\
        \hline
        \multicolumn{2}{|c|}{ } & \multicolumn{3}{c|}{3×3 max pool, stride 2} \\
        \hline
        conv2\_x & 56×56 & 
        $\left[\begin{array}{c}
        3 \times 3, 64 \\
        3 \times 3, 64
        \end{array}\right] \times 3$ & 
        $\left[\begin{array}{c}
        1 \times 1, 64 \\
        3 \times 3, 64 \\
        1 \times 1, 256
        \end{array}\right] \times 3$ & 
        $\left[\begin{array}{c}
        1 \times 1, 64 \\
        3 \times 3, 64 \\
        1 \times 1, 256
        \end{array}\right] \times 3$ \\
        \hline
        conv3\_x & 28×28 &
        $\left[\begin{array}{c}
        3 \times 3, 128 \\
        3 \times 3, 128
        \end{array}\right] \times 4$ & 
        $\left[\begin{array}{c}
        1 \times 1, 128 \\
        3 \times 3, 128 \\
        1 \times 1, 512
        \end{array}\right] \times 4$ & 
        $\left[\begin{array}{c}
        1 \times 1, 128 \\
        3 \times 3, 128 \\
        1 \times 1, 512
        \end{array}\right] \times 4$ \\
        \hline
        conv4\_x & 14×14 & 
        $\left[\begin{array}{c}
        3 \times 3, 256 \\
        3 \times 3, 256
        \end{array}\right] \times 6$ & 
        $\left[\begin{array}{c}
        1 \times 1, 256 \\
        3 \times 3, 256 \\
        1 \times 1, 1024
        \end{array}\right] \times 6$ & 
        $\left[\begin{array}{c}
        1 \times 1, 256 \\
        3 \times 3, 256 \\
        1 \times 1, 1024
        \end{array}\right] \times 23$ \\
        \hline
        conv5\_x & 7×7 &
        $\left[\begin{array}{c}
        3 \times 3, 512 \\
        3 \times 3, 512
        \end{array}\right] \times 3$ &
        $\left[\begin{array}{c}
        1 \times 1, 512 \\
        3 \times 3, 512 \\
        1 \times 1, 2048
        \end{array}\right] \times 3$ & 
        $\left[\begin{array}{c}
        1 \times 1, 512 \\
        3 \times 3, 512 \\
        1 \times 1, 2048
        \end{array}\right] \times 3$ \\
        \hline
         & 1×1 & \multicolumn{3}{c|}{average pool, 1000-d fc, softmax} \\
        \hline
        \multicolumn{2}{|c|}{FLOPs} & 3.6×10\textsuperscript{9} & 3.8×10\textsuperscript{9} & 7.6×10\textsuperscript{9} \\
        \hline
    \end{tabular}
    \caption{Configuração das arquiteturas ResNet-34, ResNet-50 e ResNet-101.}
    \label{resnet-arch}
\end{table}

\subsection{DenseNet (Densely Connected Convolutional Networks)}

A arquitetura DenseNet introduziu uma nova abordagem para lidar com redes profundas e aliviar o problema de \textit{vanishing gradients}, melhorando a propagação e reuso da informação, além de diminuir o número de parâmetros. A ideia principal foi conectar cada camada a todas as camadas anteriores, formando conexões densas entre elas. Isso significa que cada camada recebe como entrada não apenas a saída da camada anterior, mas também as saídas de todas as camadas anteriores (\autoref{dense-network}). Essa abordagem permite que o modelo aprenda representações mais ricas e complexas, facilitando a extração de características relevantes para a tarefa de classificação \citep{Huang2017}.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\linewidth]{figs/dense-network.png}
    \caption{Um bloco de 5 camadas de uma DenseNet. Cada camada recebe como entrada a saída de todas as camadas anteriores.}
    \label{dense-network}
\end{figure}

O componente fundamental da DenseNet é o bloco denso (ou \textit{dense block} em inglês), que consiste em várias camadas convolucionais conectadas densamente. Cada camada dentro do bloco denso aplica três operações consecutivas: \textit{batch normalization} (BN), seguido de uma função de ativação ReLU e, por fim, uma convolução 3×3. Após a aplicação do bloco denso, uma transição (ou \textit{transition} em inglês) é realizada para reduzir a dimensão dos \textit{feature maps} usando uma camada de convolução 1×1, seguida por uma camada de \textit{average pooling} 2×2.

Portanto, a arquitetura DenseNet é composta por quatro blocos densos, cada um seguido por camadas de transição. A saída final (classificador) é obtida através de uma camada de \textit{global average pooling} e uma camada totalmente conectada com ativação \textit{softmax} para classificação. A tabela \ref{densenet-arch} apresenta a configuração das arquiteturas DenseNet-121 e DenseNet-169, que são variantes da DenseNet com diferentes profundidades. Essas arquiteturas foram escolhidas devido à sua popularidade e eficácia em tarefas de classificação de imagens, especialmente em radiografias \citep{Leung2020}.

% TODO: dar exemplos bem-sucedidos do uso de DenseNet em radiografias

\begin{table}[h]
    \centering
    \footnotesize
    \begin{tabular}{|c|c|c|c|}
        \hline
        \textbf{Camadas} & \textbf{Tamanho da saída} & \textbf{DenseNet-121} & \textbf{DenseNet-169} \\
        \hline
        Convolução & 112×112 & \multicolumn{2}{c|}{7×7 conv, stride 2} \\
        \hline
        Pooling & 56×56 & \multicolumn{2}{c|}{3×3 max pool, stride 2} \\
        \hline
        Dense Block (1) & 56×56 & 
        $\left[\begin{array}{c}
        1 \times 3 \\
        3 \times 3
        \end{array}\right] \times 6$ & 
        $\left[\begin{array}{c}
        1 \times 3 \\
        3 \times 3
        \end{array}\right] \times 6$ \\
        \hline
        \multirow{2}{*}{Transition Layer (1)} & 56×56 & \multicolumn{2}{c|}{$1 \times 1$ conv} \\
        \cline{2-4}
        & 28×28 & \multicolumn{2}{c|}{$2 \times 2$ average pool, stride 2} \\
        \hline
        Dense Block (2) & 28×28 & 
        $\left[\begin{array}{c}
        1 \times 3 \\
        3 \times 3
        \end{array}\right] \times 12$ & 
        $\left[\begin{array}{c}
        1 \times 3 \\
        3 \times 3
        \end{array}\right] \times 12$ \\
        \hline
        \multirow{2}{*}{Transition Layer (2)} & 28×28 & \multicolumn{2}{c|}{$1 \times 1$ conv} \\
        \cline{2-4}
        & 14×14 & \multicolumn{2}{c|}{$2 \times 2$ average pool, stride 2} \\
        \hline
        Dense Block (3) & 14×14 & 
        $\left[\begin{array}{c}
        1 \times 3 \\
        3 \times 3
        \end{array}\right] \times 24$ & 
        $\left[\begin{array}{c}
        1 \times 3 \\
        3 \times 3
        \end{array}\right] \times 32$ \\
        \hline
        \multirow{2}{*}{Transition Layer (3)} & 14×14 & \multicolumn{2}{c|}{$1 \times 1$ conv} \\
        \cline{2-4}
        & 7×7 & \multicolumn{2}{c|}{$2 \times 2$ average pool, stride 2} \\
        \hline
        Dense Block (4) & 7×7 & 
        $\left[\begin{array}{c}
        1 \times 3 \\
        3 \times 3
        \end{array}\right] \times 16$ & 
        $\left[\begin{array}{c}
        1 \times 3 \\
        3 \times 3
        \end{array}\right] \times 32$ \\
        \hline
        \multirow{2}{*}{Classification Layer} & 1×1 & \multicolumn{2}{c|}{$7 \times 7$ global average pool} \\
        \cline{2-4}
        &  & \multicolumn{2}{c|}{1000D fully-connected, softmax} \\
        \hline
    \end{tabular}
    \caption{Configuração das arquiteturas DenseNet-121 e DenseNet-169.}
    \label{densenet-arch}
\end{table}

\subsection{Inception-v3}

A arquitetura Inception, introduzida por \cite{Szegedy2015} no contexto do desafio ILSVRC 2014, representou um avanço significativo na evolução das redes neurais convolucionais. Seu principal diferencial está na proposta de uma estrutura modular - o módulo Inception - que combina convoluções de diferentes tamanhos (1×1, 3×3, 5×5) e operações de \textit{pooling} em paralelo, promovendo o processamento de informações em múltiplas escalas (\autoref{inception-module}).

O modelo GoogLeNet, uma instância da arquitetura Inception com 22 camadas profundas, obteve o primeiro lugar no ILSVRC 2014 \citep{Russakovsky2015}, alcançando um notável desempenho em tarefas de classificação e detecção, mesmo utilizando significativamente menos parâmetros que modelos anteriores, como o VGG.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\linewidth]{figs/inception-module.png}
    \caption{Um módulo Inception.}
    \label{inception-module}
\end{figure}

A arquitetura Inception-v3 \citep{Szegedy2016} representa uma evolução significativa em relação ao modelo original Inception (GoogLeNet), incorporando diversas inovações voltadas à melhoria da eficiência computacional e da acurácia. Entre as principais contribuições estão a fatoração de convoluções em operações menores e assimétricas (\autoref{inception-module-v3}), o uso mais sistemático da normalização em lote (\textit{batch normalization}) e a adoção da técnica de \textit{label smoothing} como forma de regularização. Tais aprimoramentos resultaram em um modelo mais profundo e preciso, mantendo um custo computacional viável para aplicações práticas.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\linewidth]{figs/inception-module-v3.png}
    \caption{Um módulo Inception com fatoração de convoluções.}
    \label{inception-module-v3}
\end{figure}

A \autoref{inception-v3-arch} apresenta a configuração da arquitetura Inception-v3, com um total de 42 camadas, que inclui a fatoração de convoluções tradicionais 7×7 em convoluções 3×3. A arquitetura substitui o otimizador padrão do SGD por um otimizador mais avançado, o RMSProp, favorecendo a convergência do modelo durante o treinamento, além de utilizar classificadores auxiliares com normalização em lote nas camadas intermediárias, melhorando a propagação do sinal do gradiente e, por consequência, a eficiência do treinamento.

\begin{table}[ht]
    \centering
    \footnotesize
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \textbf{type} & \textbf{patch size/stride} & \textbf{input size} \\
        \hline
        conv & $3\times3$/2 & $299\times299\times3$ \\
        \hline
        conv & $3\times3$/1 & $149\times149\times32$ \\
        \hline
        conv padded & $3\times3$/1 & $147\times147\times32$ \\
        \hline
        pool & $3\times3$/2 & $147\times147\times64$ \\
        \hline
        conv & $3\times3$/1 & $73\times73\times64$ \\
        \hline
        conv & $3\times3$/2 & $71\times71\times80$ \\
        \hline
        conv & $3\times3$/1 & $35\times35\times192$ \\
        \hline
        $3\times$Inception &  & $35\times35\times288$ \\
        \hline
        $5\times$Inception &  & $17\times17\times768$ \\
        \hline
        $2\times$Inception &  & $8\times8\times1280$ \\
        \hline
        pool & $8\times8$ & $8\times8\times2048$ \\
        \hline
        linear & logits & $1\times1\times2048$ \\
        \hline
        softmax & classifier & $1\times1\times1000$ \\
        \hline
    \end{tabular}
    \caption{Configuração da arquitetura Inception-v3.}
    \label{inception-v3-arch}
\end{table}

Além de seu excelente desempenho na tarefa de classificação de imagens do ILSVRC 2012 \citep{Russakovsky2015}, a arquitetura Inception-v3 tem sido utilizada em outras aplicações, incluindo o diagnóstico médico. Por exemplo, \cite{Mujahid2022} adotaram a arquitetura Inception-v3 para a tarefa de classificação de pneumonia em radiografias e obtiveram resultados promissores, alcançando uma acurácia de 99,29\%, com um ensemble, e superando outros modelos, como VGG-16 e ResNet-50.

\section{Arquitetura do modelo de Vision Transformer}

A arquitetura Vision Transformer tem se detacado como uma abordagem poderosa para tarefas de visão computacional devido à sua capacidade de capturar relações globais em imagens através do mecanismo de atenção \cite{Dosovitskiy2021}. Essa abordagem permite que os modelos de ViTs alcancem ótimos resultados e superem as limitações das RNCs, que focam mais em características locais da imagem. Tal capacidade é particularmente relevante para o diagnóstico de patologias em imagens médicas, incluindo radiografias, onde o modelo é capaz de processar toda a imagem simultaneamente, associando partes distantes e próximas com igual relevância. Além disso, os ViTs também se beneficiam do \textit{transfer learning}, permitindo que os modelos sejam treinados de forma eficiente em conjuntos de dados limitados. Para esta pesquisa será feito o \textit{fine-tuning} de alguns modelos de ViT para a tarefa de classificação da OA de joelho, como o ViT-B/16, DeiT (Data-efficient Image Transformer), Swin Transformer (Shifted Window Transformer) e ResNet50-ViT-B/16. A arquitetura para os modelos de ViT pode ser vista na Figura \ref{modelo vit}.

\subsection{ViT-B/16}

O ViT-B/16 \cite{Dosovitskiy2021} é uma das primeiras variantes da arquitetura Vision Transformer, onde "B" representa o modelo base (base model) e "16" refere-se ao tamanho do \textit{patch} em que a imagem é dividida (16x16 pixels). O ViT-B/16 recebe uma imagem e a divide em \textit{patches}, tratando cada \textit{patch} como um \textit{token}, semelhante ao processamento de palavras em texto nos \textit{transformers} tradicionais. O modelo usa um mecanismo de atenção para processar os \textit{tokens} de maneira global, capturando interdependências entre diferentes regiões da radiografia. Essa abordagem permite que o ViT-B/16 compreenda melhor a estrutura geral da imagem, identificando padrões que podem se estender por grandes áreas da mesma. Este modelo pode ser especialmente eficaz para a tarefa de classificação da OA de joelho, visto que existe o padrão notável do espaçamento articular que se extende horizontalmente na radiografia.

\subsection{DeiT (Data-efficient Image Transformer)}

O DeiT \cite{Touvron2021} é uma versão otimizada dos ViTs, projetada para melhorar a eficiência no uso de dados. Enquanto os ViTs originais, como o ViT-B/16, geralmente precisam de grandes quantidades de dados para atingir um bom desempenho, o DeiT foi projetado para ser treinado em conjunto de dados reduzidos. Isso acontece devido à técnica do \textit{ditillation token}, que permite ao modelo aprender a partir de um "professor" (modelo mais simples), aumentando a eficiência do treinamento. Este modelo pode ser particularmente útil na tarefa de classificação da OA de joelho, podendo ser um importante fator ao comparar com outros modelos de ViTs e RNCs.

\subsection{Swin Transformer (Shifted Window Transformer)}

O Swin Transformer \cite{Liu2021} é uma arquitetura de ViT que introduz uma abordagem nova que utiliza \textit{hierarchical feature maps} e \textit{sliding windows} para aplicar a atenção e melhorar a eficiência e performance do modelo. Em vez de processar toda a imagem como uma sequência de \textit{patches} globalmente, o Swin Transformer aplica a atenção dentro de pequenas janelas locais, de forma hierárquica, permitindo que o modelo mantenha a eficiência computacional e ainda capture detalhes locais e globais. Conforme o modelo avança pelas camadas, as janelas se expandem e se deslocam, permitindo que o modelo agregue contexto global ao longo do processamento. Essa estrutura hierárquica é particularmente eficaz para imagens de alta resolução, como as radiografias, onde há muitos detalhes importantes em diferentes escalas. Além disso, o Swin Transformer pode ser facilmente escalado para diferentes tamanhos de imagens e é altamente eficiente em termos de uso de memória e poder computacional, sendo uma escolha apropriada para a tarefa de classificação da OA de joelho.

% \subsection{ResNet50-ViT-B/16}

% Uma abordagem híbrida, combinando RNC, como o ResNet, e ViT, pode ser aplicada de maneira eficaz na classificação da severidade da osteoartrite de joelho, aproveitando as vantagens de ambas as arquiteturas para obter uma melhor predição das classificações de KL \cite{Park2022, Wang2021}. Essa mescla pode ser observada no modelo ResNet50-ViT-B/16, onde o ResNet50 atua como um extrator de características iniciais, processando as radiografias e capturando padrões como texturas e bordas, e o modelo ViT-B/16 utiliza seus mecanismos de atenção para permitir uma análise mais contextualizada e eficiente. A combinação se faz promissora para melhorar a precisão na classificação da OA de joelho, equilibrando eficiência computacional e qualidade do modelo final.

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{figs/modelo-vit.png}
    \caption{Metodologia para os vision transformers}
    \label{modelo vit}
\end{figure}

\section{Métricas de avaliação}

Para comparar a performance dos modelos treinados na tarefa de classificação da severidade da OA de joelho, serão utilizadas as seguintes métricas de avaliação: acurácia, precisão, revocação, F1-score e matriz de confusão. Essas métricas são amplamente utilizadas em problemas de classificação para medir a qualidade das previsões e o equilíbrio entre os diferentes tipos de erros. Para o cálculo das métricas, os seguintes acrônimos serão utilizados nas fórmulas:

\begin{itemize}
    \item $TP$ é o número de verdadeiros positivos,
    \item $TN$ é o número de verdadeiros negativos,
    \item $FP$ é o número de falsos positivos,
    \item $FN$ é o número de falsos negativos.
\end{itemize}

\subsection{Acurácia}
A acurácia mede a proporção de previsões corretas em relação ao total de exemplos. Ela pode ser calculada pela fórmula:

\begin{equation}
    \text{Acurácia} = \frac{TP + TN}{TP + TN + FP + FN}
\end{equation}

\subsection{Precisão}
A precisão indica a proporção de exemplos classificados como positivos que realmente são positivos. Ela é calculada pela fórmula:

\begin{equation}
    \text{Precisão} = \frac{TP}{TP + FP}
\end{equation}

\subsection{Recall}
O recall mede a capacidade do modelo de identificar corretamente todos os exemplos positivos. É definido como:

\begin{equation}
    \text{Recall} = \frac{TP}{TP + FN}
\end{equation}

\subsection{F1-Score}
O F1-score é a média harmônica entre precisão e recall, e é uma métrica útil quando busca-se um equilíbrio entre os dois. A fórmula do F1-score é:

\begin{equation}
    F1 = 2 \cdot \frac{\text{Precisão} \cdot \text{Recall}}{\text{Precisão} + \text{Recall}}
\end{equation}

\subsection{Matriz de Confusão}
A matriz de confusão é uma ferramenta para visualizar o desempenho do modelo de classificação, detalhando as previsões corretas e incorretas em cada classe. Ela apresenta os valores de $TP$, $TN$, $FP$ e $FN$ de forma estruturada, permitindo avaliar o desempenho em classes específicas.

\[
\begin{array}{|c|c|c|}
\hline
 & \text{Previsto Positivo} & \text{Previsto Negativo} \\
\hline
\text{Verdadeiro Positivo} & TP & FN \\
\hline
\text{Verdadeiro Negativo} & FP & TN \\
\hline
\end{array}
\]

\subsection{AUC-ROC}
Para tarefas de classificação binária, será utilizada também a métrica AUC-ROC (Área Sob a Curva da Característica de Operação do Receptor), que mede a capacidade do modelo de separar as classes positivas e negativas. A curva ROC é um gráfico que exibe a taxa de verdadeiros positivos (sensibilidade) em função da taxa de falsos positivos.

\begin{equation}
    \text{AUC-ROC} = \int_{0}^{1} \text{TPR}(FPR) dFPR
\end{equation}

onde $TPR$ é a taxa de verdadeiros positivos e $FPR$ é a taxa de falsos positivos.

\section{Eficiência computacional}

Além da performance dos modelos, a eficiência computacional é um fator importante a ser considerado devido ao custo associado ao treinamento e inferência dos modelos. Para avaliar essa métrica, serão considerados o tempo de treinamento e a quantidade de computação utilizada por cada modelo. O tempo de treinamento, medido em minutos, é calculado da seguinte forma:

\begin{equation}
    \text{Tempo de Treinamento} = \text{Tempo Final} - \text{Tempo Inicial}
\end{equation}

onde o tempo final é o momento em que o treinamento é concluído e o tempo inicial é o momento em que ele é iniciado. A quantidade de computação é medida em FLOPs (operações de ponto flutuante por segundo), que representa uma métrica largamente utilizada para medir a quantidade de cálculos necessários para treinar um modelo de aprendizado profundo e está diretamente relacionada à eficiência computacional. A quantidade de FLOPs pode ser calculada de uma forma aproximada a partir do número de operações nas etapas de \textit{forward} e \textit{backward} do modelo, o número de exemplos no conjunto de dados e o número de épocas de treinamento \cite{Lohn2022}. Para esta pesquisa, será utilizada a biblioteca \textit{FLOPs Counter PyTorch} \cite{ptflops} para calcular a quantidade de FLOPs de cada modelo.

\section{Método de visualização}

A visualização é uma técnica importante para avaliar quais foram as regiões da imagens que ajudaram o modelo a fazer determinada previsão. O método de visualização Grad-CAM (Gradient-weighted Class Activation Mapping) é uma técnica usada para interpretar e visualizar as decisões feitas por redes neurais convolucionais (RNCs). Em tarefas de classificação, como a avaliação da severidade da OA de joelho a partir de radiografias, entender quais regiões da imagem contribuíram para a decisão do modelo é crucial para a validação e a confiança nos resultados do modelo.

O Grad-CAM fornece mapas de ativação que mostram quais partes da imagem foram mais influentes para a predição de uma classe específica \cite{Selvaraju2016}. Para isso, essa técnica utiliza os gradientes da saída da camada final da rede em relação às ativações das camadas intermediárias para gerar uma visualização da importância das regiões da imagem.

Primeiro, é gerado um mapa de localização a partir da RNC utilizada para classificar a imagem usando a técnica do Class Activation Mapping (CAM). O CAM utiliza mapas de características convolucionais, que são globalmente agrupados usando a técnica de \textit{Global Average Pooling} (GAP) e transformados linearmente para produzir uma pontuação \( y_c \) para cada classe \( c \). Especificamente, se a penúltima camada da RNC produz \( K \) mapas de características \( A_k \in \mathbb{R}^{u \times v} \), esses mapas são agrupados espacialmente e combinados linearmente para gerar a pontuação:

\[
y_c = \sum_k w_{ck} \frac{1}{Z} \sum_i \sum_j A_{k_{ij}}
\]

Para produzir o mapa de localização \( L_c^{CAM} \) para a classe \( c \), CAM calcula a combinação linear dos mapas de características finais usando os pesos aprendidos da camada final:

\[
L_c^{CAM} = \sum_k w_{ck} A_k
\]

Este mapa é então normalizado para o intervalo entre 0 e 1 para fins de visualização.

Em seguida, os gradientes são então globalmente averiguados (\textit{pooling}) para obter pesos que indicam a importância de cada canal de ativação. Esses pesos são usados para ponderar as ativações da camada convolucional final. A seguinte fórmula representa este cálculo dos pesos:

\[
\alpha_{k}^{c} = \frac{1}{Z} \sum_i \sum_j \frac{\partial y^{c}}{\partial A_{ij}^{k}}
\]

O peso \( \alpha_{k}^{c} \) representa a linearização parcial da rede e captura a importância de \(k \) para a classe \(c \). Por fim, o mapa de ativação é obtido ao multiplicar as ativações ponderadas pelos pesos dos gradientes. Esse mapa é então normalizado e sobreposto na imagem original para mostrar as áreas mais influentes na decisão do modelo.

A fórmula para o Grad-CAM pode ser expressa como:

\[
\text{Grad-CAM} = \text{ReLU} \left( \sum_{k} \alpha_{k}^{c} A^{k} \right)
\]

Para esta pesquisa, a utilização do Grad-CAM permitirá a visualização das regiões das radiografias que o modelo considera mais relevantes para suas decisões de classificação. Isso não só facilita a interpretação dos resultados do modelo, mas também ajuda na validação de sua eficácia ao garantir que o modelo está focando nas áreas corretas da imagem, como o espaço articular do joelho.