\chapter{Metodologia}\label{cap:proposta}

Esta seção descreve a metodologia proposta para a tarefa de classificação da OA de joelho a partir de radiografias. A principal abordagem desta pesquisa consiste no uso de \textit{transfer learning} para aproveitar o conhecimento já obtido por modelos pré-treinados e melhorar a performance da predição final.

\section{Coleta de dados}

A seleção e coleta de dados constituem etapas iniciais fundamentais no desenvolvimento de modelos de aprendizado profundo. Nesse estudo, o conjunto de dados (ou \textit{dataset} do inglês) foi obtido por meio da plataforma Kaggle \citep{dataset-kaggle}, amplamente reconhecida por disponibilizar dados de alta qualidade e de acesso público para fins acadêmicos. O \textit{dataset} escolhido baseia-se na Osteoarthritis Initiative (OAI) e contém 9.786 radiografias de joelho rotuladas com suas respectivas classificações de severidade da OA, seguindo o sistema de Kellgren-Lawrence (\autoref{tabela-kl}). A escolha desta fonte deve-se à sua ampla utilização na plataforma e na literatura \citep{Tariq2023, Mohammed2023}, além do volume de imagens, fornecendo uma base sólida e representativa para o treinamento e avaliação dos modelos propostos. Um resumo do \textit{dataset} é apresentado na \autoref{dataset-summary}.

\begin{table}[ht]
    \centering
    \begin{tabular}{|c|c|c|c|}
        \hline
        \textbf{Classe KL} & \textbf{Descrição} & \textbf{Total de imagens} & \textbf{\% do total} \\
        \hline
        0 & saudável & 3857 & 40\% \\
        1 & duvidoso & 1770 & 18\% \\
        2 & mínimo & 2578 & 26\% \\
        3 & moderado & 1286 & 13\% \\
        4 & severo & 295 & 3\% \\
        \hline
        \textbf{Total} & - & 9786 & 100\% \\
        \hline
    \end{tabular}
    \caption{Número de radiografias por classe KL no conjunto de dados original.}
    \label{dataset-summary}
\end{table}

Todas as imagens possuem resolução de 224x224 pixels e estão no formato PNG. As imagens foram agrupadas em subconjuntos de treino, teste, validação e calibração, com uma proporção de 7:1:1:1. O conjunto de treino é utilizado para treinar os modelos, o conjunto de validação é usado para ajustar os hiperparâmetros e monitorar o desempenho do modelo durante o treinamento, o conjunto de teste é utilizado para avaliar o desempenho final do modelo e verificar sua capacidade de generalização em dados novos, e o conjunto de calibração é usado para aplicar a estratégia de predição conformal, discutida na \autoref{sec:conformal-prediction}. A distribuição das imagens por subconjunto de dados pode ser visualizada na \autoref{dataset-distribuition}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.7\linewidth]{figs/dataset-class-distribution.png}
    \caption{Distribuição das radiografias por classe KL nos subconjuntos de treino, teste, validação e calibração.}
    \label{dataset-distribuition}
\end{figure}

Com o objetivo de explorar diferentes abordagens para a classificação da severidade da OA de joelho, foram derivados, a partir do \textit{dataset} original contendo cinco classes, três novos conjuntos de dados: com 4, 3 e 2 classes. O conjunto com 4 classes foi construído por meio da exclusão da classe 1 (duvidosa), com a finalidade de simplificar o problema de classificação. O conjunto com 3 classes foi obtido pela remoção das classes 0 e 1 (respectivamente, saudável e duvidosa), resultando em um subconjunto composto apenas pelas instâncias que apresentavam algum grau de severidade (mínima, moderada ou severa). Por fim, o conjunto com 2 classes foi gerado ao se agrupar as classes 0 e 1, representando a ausência de OA, e as classes 2, 3 e 4, representando a presença de OA, formando, assim, um conjunto de dados binário.

\section{Pré-processamento das imagens}

A etapa de pré-processamento é essencial para garantir que as imagens estejam em um formato adequado para o treinamento dos modelos. Neste estudo, o pré-processamento das radiografias foi dividido em duas etapas: pré-processamento geral e pré-processamento específico para cada modelo. O pré-processamento geral, realizado antes do treinamento, inclui técnicas como equalização de histograma e filtro gaussiano. Já o pré-processamento específico para cada modelo, realizado durante o treinamento, envolve a adaptação das imagens às exigências de entrada dos modelos selecionados, como redimensionamento e normalização dos valores dos pixels. Além disso, o aumento de dados foi aplicado para expandir a variabilidade do conjunto de dados e mitigar o efeito do desbalanceamento entre as classes.

\subsection{Equalização de Histograma}

A equalização de histograma foi utilizada como técnica de pré-processamento com o intuito de melhorar o contraste das radiografias coletadas do conjunto original. Esse método redistribuiu os níveis de intensidade dos pixels de forma a abranger a maior faixa de valores possíveis, aumentando a separabilidade entre as regiões mais claras e mais escuras da radiografia. Em particular, essa técnica foi útil para realçar o contraste das estruturas ósseas e o espaço articular do joelho, assim como alterações ósseas sutis que podem ser indicativas de OA.

A aplicação da equalização de histograma foi realizada utilizando a biblioteca OpenCV \citep{opencv} do Python. A \autoref{fig:histogram-equalization}(a) ilustra uma radiografia original do joelho, enquanto a \autoref{fig:histogram-equalization}(b) mostra a mesma radiografia após a equalização de histograma. É possível observar que a equalização melhorou o contraste da imagem, tornando as estruturas ósseas mais visíveis. As respectivas distribuições de intensidade dos pixels antes e depois da equalização são apresentadas na \autoref{fig:histogram-equalization-histogram}.

\begin{figure}
    \centering
    \begin{tabular}{@{}c@{}}
        \includegraphics[width=0.45\textwidth]{figs/imagem-nao-equalizada.png} \\[\abovecaptionskip]
        \small (a) Radiografia original do joelho.
    \end{tabular}
    \hfill
    \begin{tabular}{@{}c@{}}
        \includegraphics[width=0.45\textwidth]{figs/image-equalizada.png} \\[\abovecaptionskip]
        \small (b) Radiografia após equalização de histograma.
    \end{tabular}
    \caption{Exemplo de equalização de histograma aplicada a uma radiografia de joelho.}
    \label{fig:histogram-equalization}
\end{figure}

\begin{figure}
    \centering
    \begin{tabular}{@{}c@{}}
        \includegraphics[width=0.45\textwidth]{figs/histograma-imagem-nao-equalizada.png} \\[\abovecaptionskip]
        \small (a) Histograma da radiografia original.
    \end{tabular}
    \hfill
    \begin{tabular}{@{}c@{}}
        \includegraphics[width=0.45\textwidth]{figs/histograma-imagem-equalizada.png} \\[\abovecaptionskip]
        \small (b) Histograma da radiografia após equalização.
    \end{tabular}
    \caption{Distribuições de intensidade dos pixels antes e depois da equalização de histograma.}
    \label{fig:histogram-equalization-histogram}
\end{figure}

\subsection{Normalização}

A normalização das radiografias consistiu em uma etapa fundamental do pré-processamento, com o objetivo de padronizar a escala dos valores dos pixels e, assim, facilitar o aprendizado pelos modelos. Essa técnica foi aplicada convertendo os valores de intensidade dos pixels, originalmente na faixa de 0 a 255, para uma faixa padronizada entre 0 e 1.

Neste estudo, a normalização foi implementada em todos os subconjuntos de dados utilizando a função \texttt{transforms.Normalize} da biblioteca PyTorch \citep{pytorch}, que aplica a normalização em cada canal (RGB), subtraindo a média e dividindo pelo desvio padrão. Para modelos baseados em arquiteturas tradicionais, como ResNet e VGG, utilizaram-se os valores convencionais:

\begin{itemize}
    \item Média: 0.485, 0.456 e 0.406
    \item Desvio padrão: 0.229, 0.224 e 0.225
\end{itemize}

Para modelos baseados em ViTs, como o DeiT e o Swin Transformer, foram utilizados os valores de normalização específicos para esses modelos, obtidos diretamente do objeto \texttt{processor}, utilizando a função \texttt{processor.image\_mean} e \texttt{processor.image\_std}, garantindo a compatibilidade com o pré-processamento original desses modelos.

\subsection{Aumento de dados}

Com o objetivo de melhorar a generalização dos modelos e reduzir o risco de \textit{overfitting}, foi aplicado o aumento de dados (\textit{data augmentation}) nas radiografias durante o treinamento dos modelos.

A técnica consistiu na aplicação de transformações geométricas simples nas imagens do conjunto de treinamento, de forma a simular variações naturais que poderiam ocorrer nas radiografias. As transformações incluíram a inversão horizontal (reflexão), com probabilidade de 50\%, e rotações aleatórias limitadas a um intervalo de -10 a 10 graus.

Antes das transformações, as imagens foram redimensionadas para o tamanho esperado pelo modelo, definido como 224x224 pixels para todos os modelos, exceto para o modelo InceptionV3, que requer imagens de 299x299 pixels.

\subsection{Subamostragem}

Como pode ser observado na \autoref{dataset-summary}, o conjunto de dados original apresenta um desbalanceamento significativo entre as classes, com a classe 0 (saudável) representando 40\% do total de imagens e a classe 4 (severo) apenas 3\%. Para lidar com esse desbalanceamento, além do aumento de dados, foi aplicada a técnica de subamostragem (\textit{undersampling}) nas classes majoritárias e reduzindo o número de imagens dessas classes, equilibrando sua proporção em relação às classes minoritárias.

A subamostragem foi aplicada apenas no conjunto de treinamento, de modo a não comprometer a representatividade das distribuições no conjunto de validação, testes e calibração. A técnica consistiu na seleção aleatória de um subconjunto das amostras das classes até um limite definido de 1.700 imagens por classe. Esse limite foi escolhido com base na classe 2 (mínima), que possui o maior número de imagens entre as classes com severidade, garantindo que todas as classes fossem representadas de forma equilibrada no conjunto de treinamento.

Embora essa estratégia possa levar à perda de informações potencialmente úteis, ela ajuda a reduzir o viés do modelo em direção às classes majoritárias e melhora sua capacidade de aprender padrões relevantes em todas as classes.