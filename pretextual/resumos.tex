% ---
% RESUMOS
% ---

% RESUMO em português
\setlength{\absparsep}{18pt} % ajusta o espaçamento dos parágrafos do resumo
\begin{resumo}
  A osteoartrite (OA) de joelho é uma das condições articulares mais comuns e incapacitantes no mundo, sendo caracterizada como uma doença progressiva que afeta principalmente a cartilagem do joelho. Embora não tenha cura, a detecção precoce é fundamental para prevenir sua progressão, e a radiografia é a principal técnica utilizada para o diagnóstico da OA e para sua classificação com base na escala de Kellgren/Lawrence (KL). No entanto, o diagnóstico radiológico depende da experiência, interpretação e tempo do profissional, o que pode gerar inconsistências ou erros. Nesse contexto, técnicas de aprendizado profundo oferecem uma alternativa mais rápida e eficiente, permitindo a automação da detecção e classificação da OA de joelho.

  Este estudo propõe uma comparação entre modelos de redes neurais convolucionais (RNCs) e vision transformers (ViTs) na tarefa de classificar a severidade da OA de joelho, abrangendo os modelos ResNet-34, ResNet-50, ResNet-101, VGG-16, VGG-19, DenseNet-121, DenseNet-169, Inception-v3, DeiT, Swin Transformer, DaViT, MaxViT e GCViT. O treinamento dos modelos foi realizado com o uso de aprendizado por transferência, e a análise comparativa considera métricas de performance, consumo computacional, análise quantitativa de incerteza e interpretabilidade. Os resultados mostraram que as arquiteturas RNCs, especialmente aquelas da família DenseNet apresentaram o melhor desempenho geral, com o modelo DenseNet-169 alcançando uma acurácia de 78,85\%. Em termos de eficiência computacional, as RNCs foram significativamente mais rápidas, com o DenseNet-121 oferecendo o melhor equilíbrio entre alto desempenho preditivo (QWK de 0,8878) e baixo custo de treinamento e inferência (3,11 ms/imagem). Os ViTs, apesar de competitivos, apresentaram um desempenho inferior com um custo computacional maior. Finalmente, a análise de interpretabilidade com Grad-CAM confirmou que os modelos de melhor desempenho baseiam suas decisões em marcadores patológicos relevantes, como o espaço articular e osteófitos.

  \vspace{\onelineskip}

 \textbf{Palavras-chaves}: Classificação. osteoartrite de joelho. radiografias. redes neurais convolucionais. transfer-learning. vision transformers.
\end{resumo}

% ABSTRACT in english
\begin{resumo}[Abstract]
 \begin{otherlanguage*}{english}
  Knee osteoarthritis (OA) is one of the most common and disabling joint conditions worldwide. It is characterized as a progressive disease that primarily affects the knee cartilage. Although it has no cure, early detection is crucial to prevent its progression. Radiography is the main technique used for diagnosing OA and for classifying it based on the Kellgren/Lawrence (KL) scale. However, radiological diagnosis depends on the experience, interpretation, and time of the professional, which can lead to inconsistencies or errors. In this context, deep learning techniques offer a faster and more efficient alternative, enabling the automation of OA detection and classification.

  This study proposes a comparison between convolutional neural networks (CNNs) and vision transformers (ViTs) for the task of classifying knee OA severity, including models such as ResNet-34, ResNet-50, ResNet-101, VGG-16, VGG-19, DenseNet-121, DenseNet-169, Inception-v3, DeiT, Swin Transformer, DaViT, MaxViT, and GCViT. The models were trained using transfer learning, and the comparative analysis considers performance metrics, computational cost, quantitative uncertainty analysis, and interpretability. The results showed that CNN architectures, particularly those from the DenseNet family, achieved the best overall performance, with the DenseNet-169 model reaching an accuracy of 78.85\%. In terms of computational efficiency, CNNs were significantly faster, with DenseNet-121 offering the best balance between high predictive performance (QWK of 0.8878) and low training and inference cost (3.11 ms/image). Although competitive, ViTs showed lower performance and higher computational cost. Finally, the interpretability analysis using Grad-CAM confirmed that the top-performing models base their decisions on relevant pathological markers, such as joint space and osteophytes.

   \vspace{\onelineskip}
 
   \noindent 
   \textbf{Keywords}: Classification. convolutional neural networks. knee osteoarthritis. radiographs. transfer-learning. vision transformers.
 \end{otherlanguage*}
\end{resumo}